{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classification Example with TensorFlow\n",
    "Supervised problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import or generate data.\n",
    "All of our machine learning algorithms will depend on data. In this book we will either generate data or use an outside source of data. Sometimes it is better to rely on generated data because we will want to know the expected outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('input/data.csv')\n",
    "\n",
    "dataframe = dataframe.drop(['index', 'price', 'sq_price'],axis=1)\n",
    "dataframe = dataframe[0:10]\n",
    "print (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add labels\n",
    "# 1 is good buy and 0 is bad buy\n",
    "dataframe.loc[:, ('y1')]  = [1,0,1,1,0,1,1,0,0,1]\n",
    "\n",
    "#y2 is the negation of the y1\n",
    "dataframe.loc[:, ('y2')] = dataframe['y1'] == 0\n",
    "\n",
    "# convert true/false value to 1s and 0s\n",
    "dataframe.loc[:, ('y2')] = dataframe['y2'].astype(int)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputX = dataframe.loc[:, ['area','bathrooms']].as_matrix()\n",
    "inputY = dataframe.loc[:, ['y1','y2']].as_matrix()\n",
    "inputX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set algorithm parameters.\n",
    "Our algorithms usually have a set of parameters that we hold constant throughout the procedure. For example, this can be the number of iterations, the learning rate, or other fixed parameters of our choosing. It is considered good form to initialize these together so the reader or user can easily find them.\n",
    "learning_rate = 0.01  iterations = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.00001\n",
    "training_epochs = 2000 #iterations\n",
    "display_steps = 50\n",
    "n_samples = inputY.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables and placeholders.\n",
    "Tensorflow depends on us telling it what it can and cannot modify. Tensorflow will modify the variables during optimization to minimize a loss function. To accomplish this, we feed in data through placeholders. We need to initialize both of these, variables and placeholders with size and type, so that Tensorflow knows what to expect.\n",
    "a_var = tf.constant(42)  x_input = tf.placeholder(tf.float32, [None, input_size])  y_input = tf.placeholder(tf.fload32, [None, num_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create our computation graph/ Neural Network\n",
    "# for feature input tensors, none means any numbers of examples\n",
    "# placgeholder are gateways for data into our computation\n",
    "x = tf.placeholder(tf.float32, [None,2])\n",
    "\n",
    "#create weights\n",
    "# 2 X 2 float matrix, that we'll keep updateing through the training process\n",
    "w = tf.Variable(tf.zeros([2,2]))\n",
    "\n",
    "#create bias , we have 2 bias since we have two features\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "y_values = tf.add(tf.matmul(x,w),b)\n",
    "\n",
    "y = tf.nn.softmax(y_values)\n",
    "\n",
    "# For trainign purpose, we'll also feed a matrix of labels\n",
    "y_ = tf.placeholder(tf.float32, [None,2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model structure.\n",
    "After we have the data, and initialized our variables and placeholders, we have to define the model. This is done by building a computational graph. We tell Tensorflow what operations must be done on the variables and placeholders to arrive at our model predictions. We talk more in depth about computational graphs in chapter two, section one of this book.\n",
    "y_pred = tf.add(tf.mul(x_input, weight_matrix), b_matrix)\n",
    "### Declare the loss functions.\n",
    "After defining the model, we must be able to evaluate the output. This is where we declare the loss function. The loss function is very important as it tells us how far off our predictions are from the actual values. The different types of loss functions are explored in greater detail in chapter two, section five.\n",
    "loss = tf.reduce_mean(tf.square(y_actual – y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cost function: Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(y_ - y, 2))/(2*n_samples)\n",
    "# Gradient Descent \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and train the model.\n",
    "Now that we have everything in place, we create an instance or our graph and feed in the data through the placeholders and let Tensorflow change the variables to better predict our training data. Here is one way to initialize the computational graph.\n",
    "with tf.Session(graph=graph) as session:\n",
    " ...\n",
    " session.run(...)\n",
    " ...\n",
    "Note that we can also initiate our graph with\n",
    "session = tf.Session(graph=graph)  session.run(…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialize variables and tensorflow session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model.\n",
    "Once we have built and trained the model, we should evaluate the model by looking at how well it does on new data through some specified criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now for the actual training \n",
    "for i in range(training_epochs):\n",
    "    #Take a gradient descent step using our input and labels \n",
    "    sess.run(optimizer, feed_dict={x: inputX, y_:inputY})\n",
    "     \n",
    "    # Display logs per epoch step   \n",
    "    if (i)  % display_steps == 0:\n",
    "        cc = sess.run(cost, feed_dict={x: inputX, y_: inputY})\n",
    "        print(\"Training step:\", '%04d' % (i), \"Cost: :\", \"{:.9f}\".format(cc) )\n",
    "    \n",
    "print(\"Optimization Done!\")\n",
    "training_cost = sess.run(cost, feed_dict={x: inputX, y_: inputY})\n",
    "print (\"Training cost=\", training_cost, \"W=\", sess.run(w), \"b=\", sess.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict new outcomes.\n",
    "It is also important to know how to make predictions on new, unseen, data. We can do this with all of our models, once we have them trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(y, feed_dict={x:inputX})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
